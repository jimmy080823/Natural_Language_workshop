{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP4167 Natural Language Processing\n",
    "# Practical I - Part I\n",
    "# Tokenization, Term-Document Matrix, TF-IDF and Text classification\n",
    "\n",
    "In this notebook you will practice some of the methods discusssed in the lectures to address an NLP task, text classification.\n",
    "\n",
    "In this notebook you will:\n",
    "- Perform the process of tokenization\n",
    "- Build a Term-Document Matrix (using some methods like Counting words and TFIDF) as the feature extraction method\n",
    "- Apply a machine learning classifier to predict or classify a tweet as real or fake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "Emergency agencies started using social media and especially Twitter to identify quickly when disasters are hppening. In this problem,youâ€™re tasked to build a machine learning model that predicts which Tweets are related to real disaster and which are not relevant. The dataset has 10,000 tweets that were manually classified.\n",
    "\n",
    "This is a [Kaggle competition](https://www.kaggle.com/c/nlp-getting-started) to getting started in NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries\n",
    "\n",
    "- make sure the libraries are already installed using pip or conda\n",
    "- install the latest version of the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve,auc,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the data for pre-processing \n",
    "\n",
    "Data are assumed to be in the 'data' folder which includes two files:\n",
    "- `train.csv`: the training data set\n",
    "- `test.csv`: the testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_name = 'data'\n",
    "train_filename = 'train.csv'\n",
    "\n",
    "train_path = data_folder_name +'/'+ train_filename \n",
    "\n",
    "# Relevant columns for this exercise \n",
    "TEXT_COLUMN = 'text'\n",
    "TARGET_COLUMN = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample in the train and test set has the following information:\n",
    "\n",
    "- The text of a tweet\n",
    "- A keyword from that tweet (although this may be blank!)\n",
    "- The location the tweet was sent from (may also be blank)\n",
    "\n",
    "The task is to predict whether a given tweet is about a real disaster (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tweets of the train dataset\n",
    "# we will use this data for the training by spliting it into further training and validation set\n",
    "data = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some data from the training set\n",
    "# re-running the cell will produce another sample\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the text and target columns from our dataframe, \n",
    "# for this exercise we will assume the other fields are not important\n",
    "data = data[[TEXT_COLUMN, TARGET_COLUMN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample 10 strings of class 1 (disaster)\n",
    "list(data[data['target']==1].sample(10)['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10 strings of class 0 (not a disaster)\n",
    "list(data[data['target']==0].sample(10)['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train and test set\n",
    "\n",
    "We split the train dataset into a train and validation dataset so we can evaluate the result with cross-validation. \n",
    "- we use 80-20 data split\n",
    "- set the random_state which help re-producing the same results every time we run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data[TEXT_COLUMN], \n",
    "                                                  data[TARGET_COLUMN].values,\n",
    "                                                  test_size=0.20,\n",
    "                                                  random_state=0)\n",
    "# check the size of our datasets\n",
    "print('Size of training set:',X_train.shape)\n",
    "print('Size of validation set:',X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "In this exercise we will extract TF/IDF features.\n",
    "- We will use the implmentation of TF/IDF in scikit-learn\n",
    "- In the implmentation we will use lower case \n",
    "- We will drop the words that occured less than two times in the documents\n",
    "- The TF/IDF vectorizer is built on the training data and is then used to extract features from both training and validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try multiple ways of calculating features.\n",
    "#   Create the numericalizer TFIDF for lowercase\n",
    "tfidf = TfidfVectorizer(decode_error='ignore', lowercase=True, min_df=2)\n",
    "#   Numericalize the train dataset\n",
    "train = tfidf.fit_transform(X_train.values.astype('U'))\n",
    "#   Numericalize the test dataset\n",
    "val = tfidf.transform(X_val.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train size: ',train.shape)\n",
    "print('Val size: ',val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample some words from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = np.asarray(tfidf.get_feature_names_out())\n",
    "print(dictionary[np.random.randint(0,len(dictionary),size=20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models\n",
    "\n",
    "The extracted features will be used to train classifiers in to order to predict which tweets belong to class 0 or class 1.\n",
    "\n",
    "We will test here three classifiers: \n",
    "- Naive Bayes\n",
    "- SVM\n",
    "- XBGboost Classifier\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "One of the most commonly used classifier for text classification: Naive Bayes using multinomial models. \n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the model, train it on the train dataset and print the scores\n",
    "model = MultinomialNB() # as implemented in sklearn\n",
    "model.fit(train, y_train)\n",
    "print(\"Train score:\", model.score(train, y_train))\n",
    "print(\"Validation score:\", model.score(val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Naive Bayes classifier\n",
    "First we create some helper functions to plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    ''' Plot the confusion matrix for the target labels and predictions '''\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Create a dataframe with the confusion matrix values\n",
    "    df_cm = pd.DataFrame(cm, range(cm.shape[0]),\n",
    "                  range(cm.shape[1]))\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True,fmt='.0f',cmap=\"YlGnBu\",annot_kws={\"size\": 10}) # font size\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "# plot no skill\n",
    "# Calculate the points in the ROC curve\n",
    "def plot_roc_curve(y_test, y_pred):\n",
    "    ''' Plot the ROC curve for the target labels and predictions'''\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    roc_auc= auc(fpr,tpr)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    ax = plt.subplot(121)\n",
    "    ax.set_aspect(1)\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = model.predict(val)\n",
    "\n",
    "#print the classification report to highlight the accuracy with f1-score, precision and recall\n",
    "print(metrics.classification_report(y_val, y_pred))\n",
    "plot_confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# ROC curve needs the raw model probabilities, not the model predictions\n",
    "y_pred_prob = model.predict_proba(val)[:,1]\n",
    "plot_roc_curve(y_val, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suport Vector Machine Classifier\n",
    "Alternatively, we can use SVM algorithm to predict if a tweet is fake or real, it is just a binary classifcation problem. \n",
    "For SVM it is important to optimise the parameters of the kernel used. Here we use a GridSearch to optimise the hyper paramters of an RBF Kernel. A similar process can be done for other kernels like Linear or Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the parameters to tune\n",
    "parameters = { \n",
    "    'C': [1.0, 10],\n",
    "    'gamma': [1, 'auto', 'scale']\n",
    "}\n",
    "# Tune hyperparameters  using Grid Search and a SVM model\n",
    "model = GridSearchCV(SVC(kernel='rbf', probability=True), parameters, cv=5, n_jobs=-1).fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our model is trained we can evaluate the performance as we did previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the validation set \n",
    "y_pred = model.predict(val)\n",
    "\n",
    "print(metrics.classification_report(y_val, y_pred))\n",
    "plot_confusion_matrix(y_val, y_pred)\n",
    "\n",
    "y_pred_prob = model.predict_proba(val)[:,1]\n",
    "plot_roc_curve(y_val, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple SVM increases the performance of our model but not significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost classifier\n",
    "\n",
    "XGBoost is an implementation of gradient boosted decision trees designed for speed and performance. XGBoost is an advanced version of gradient boosting. Rather than training all of the models in isolation of one another, boosting trains models in succession, with each new model being trained to correct the errors made by the previous ones. Models are added sequentially until no further improvements can be made.\n",
    "\n",
    "XGBoost provides a wrapper class to allow any models to be treated like classifiers or regressors in the scikit-learn framework. This means we can use the full scikit-learn library with XGBoost models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def f1_metric(ytrue,preds):\n",
    "    ''' Return the F1 Score value for the preds and true values, ytrue '''\n",
    "    return 'f1_score', f1_score((preds>=0.5).astype('int'), ytrue, average='macro'), True\n",
    "\n",
    "# set the model parameters\n",
    "params = {\n",
    "    'learning_rate': 0.06,\n",
    "    'n_estimators': 1500,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'metric': 'f1_score'\n",
    "}\n",
    "\n",
    "full_clf = LGBMClassifier(**params)\n",
    "\n",
    "# Fit or train the xgboost model\n",
    "full_clf.fit(train.astype(np.float32), y_train, eval_set=[(train.astype(np.float32), y_train), (val.astype(np.float32), y_val)],\n",
    "             verbose=400, eval_metric=f1_metric)\n",
    "\n",
    "#Show the results\n",
    "print(\"train score:\", full_clf.score(train.astype(np.float32), y_train))\n",
    "print(\"val score:\", full_clf.score(val.astype(np.float32), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can predict on the test dataset to get the results and compare with others methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "Y_pred = full_clf.predict(val.astype(np.float32))\n",
    "\n",
    "print(metrics.classification_report(y_val, y_pred))\n",
    "plot_confusion_matrix(y_val, y_pred)\n",
    "\n",
    "y_pred_prob = model.predict_proba(val)[:,1]\n",
    "plot_roc_curve(y_val, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some results from our text\n",
    "\n",
    "Another tool we can use to analyze the results is a WordCloud where we can draw the most relevant words in the fake tweets and real tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data on a WordCloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def visualize(label):\n",
    "    words = ''\n",
    "    for msg in data[data[TARGET_COLUMN] == label][TEXT_COLUMN]:\n",
    "        msg = msg.lower()\n",
    "        words += msg + ' '\n",
    "    wordcloud = WordCloud(width=600, height=600).generate(words)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(1)\n",
    "visualize(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
